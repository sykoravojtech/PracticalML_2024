PROJECT_NAME: PracticalML
EXPERIMENT: cls_vm_ch_exp6
OUTPUT_DIR: ./runs
WANDB_KEY: 547d969d74fa2db0a0eb6a8b49490f5fddccfc04
SEED: 42

MODEL:
  TYPE: classification
  ENCODER:
    TYPE: VideoMamba
    PRETRAINED: True
    MODEL_SIZE: middle # tiny, small, middle
    HIDDEN_SIZE: 576   # 192,  384,   576
    RETURN_ALL_HIDDEN: True
    NUM_VISUAL_TOKENS: ... # Number of visual tokens' hidden states to use in the head. 
                            # If RETURN_ALL_HIDDEN is False, this is ignored.

  HEAD:
    TYPE: MLP
    LAYERS: [4096, 4096]
    DROPOUT: 0.5  # Optional: Dropout probability
    LAYER_NORM: False  # Optional: Use layer normalization
    NUM_CLASSES: 157
    MULTI_LABEL: True
    THRESHOLD: 0.5

  LOSS: BCEWithLogitsLoss
  USE_CLASS_WEIGHTS: False

DATA:
  ENCODING_DIR: data/encodings/cls_vm_charades_all_hiddens/ # path to precomputed hidden states from the encoder
  DATASET: charades_action_classification
  ROOT_PATH: data/raw/Charades
  TRAIN_CSV: Charades_per-frame_annotations_fps1.5_action_cls_train.csv
  TEST_CSV: Charades_per-frame_annotations_fps1.5_action_cls_test.csv
  IMG_SIZE: 224
  NUM_SAMPLED_FRAMES: 16
  CLIP_DURATION: 11 # we want about 16 frames, fps = 1.5 -> set clip duration to 11s
  FPS: 1.5
  MEAN: [0.45, 0.45, 0.45]
  STD: [0.225, 0.225, 0.225]
  NUM_WORKERS: 16

TRAIN:
  FREEZE_ENCODER: True
  NUM_EPOCHS: 300
  BATCH_SIZE: 32
  OPTIM:
    TYPE: AdamW
    INIT_LEARNING_RATE: 0.0001
    MIN_LEARNING_RATE: 0.000001
    EPS: 0.000001
    BETAS: [0.9, 0.999]
    LR_MILESTONES: [250,400]
  LOG_STEPS: 50
  ACCELERATOR: auto
  DEVICES: auto
  PRECISION: 32
  BEST_CHECKPOINT_BY: val_mAP
  COMPUTE_METRIC_AT_TRAIN_TIME: True
